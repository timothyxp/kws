{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "c4171a9f-1054-46a8-93a6-048b883d4d89",
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "# Import and misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.7)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.5.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.6.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (21.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (4.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (58.0.4)\n",
      "Requirement already satisfied: thop in /opt/conda/lib/python3.7/site-packages (0.0.31.post2005241907)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from thop) (1.9.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.0->thop) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install wandb\n",
    "pip install pandas\n",
    "pip install matplotlib\n",
    "pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "018b296c-b339-46b0-888a-d289b8c646ec",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meO-Mp9jiAFC",
    "outputId": "3ce0c838-cd55-4199-e590-2116cd25d35f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio==0.9.1\n",
      "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.9.1\n",
      "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s eta 0:00:019  |                                | 798 kB 2.8 MB/s eta 0:04:55     |████████                        | 208.2 MB 2.6 MB/s eta 0:04:03     |███████████▊                    | 304.6 MB 3.1 MB/s eta 0:02:48     |███████████████▎                | 397.9 MB 2.7 MB/s eta 0:02:41     |███████████████████████████████ | 803.6 MB 2.6 MB/s eta 0:00:11     |███████████████████████████████▉| 825.9 MB 3.0 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.1->torchaudio==0.9.1) (3.10.0.2)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0\n",
      "    Uninstalling torch-1.10.0:\n",
      "      Successfully uninstalled torch-1.10.0\n",
      "Successfully installed torch-1.9.1 torchaudio-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "pp7x2a12gbrym8vu4ylh5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.9.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: torchvision, torchtext, torchelastic, torchaudio\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "g3iqllfm6mrl69e1hmddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.4\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-20 10:59:29--  https://gist.githubusercontent.com/Kirili4ik/6ac5c745ff8dad094e9c464c08f66f3e/raw/63daacc17f52a7d90f7f4166a3f5deef62b165db/dataset_utils.py\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3475 (3.4K) [text/plain]\n",
      "Saving to: ‘dataset_utils.py’\n",
      "\n",
      "dataset_utils.py    100%[===================>]   3.39K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-20 10:59:29 (7.11 MB/s) - ‘dataset_utils.py’ saved [3475/3475]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://gist.githubusercontent.com/Kirili4ik/6ac5c745ff8dad094e9c464c08f66f3e/raw/63daacc17f52a7d90f7f4166a3f5deef62b165db/dataset_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "4fxkj6232s9mgeefm6ax0n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "d2d47464-5bb4-4699-aa25-cfd2981eaa57",
    "id": "bbUpoArCqUYa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f070ba21e90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "from typing import Tuple, Union, List, Callable, Optional\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import pathlib\n",
    "import dataclasses\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "a95aca1f-c38d-47ba-8b82-dd6a9a00ce80",
    "id": "812GwLfqqUYf"
   },
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "f184ec76-891c-40e4-8131-80622b75b451",
    "id": "i1DuQIyRqUYf"
   },
   "source": [
    "In this notebook we will implement a model for finding a keyword in a stream.\n",
    "\n",
    "We will implement the version with CRNN because it is easy and improves the model. \n",
    "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "cellId": "0e5775b5-b55f-43e9-b835-29b0b92996ec",
    "id": "8PdhApeEh9pH"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "@dataclasses.dataclass\n",
    "class TaskConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    num_epochs: int = 40\n",
    "    n_mels: int = 40\n",
    "    cnn_out_channels: int = 8\n",
    "    kernel_size: Tuple[int, int] = (5, 20)\n",
    "    stride: Tuple[int, int] = (2, 8)\n",
    "    hidden_size: int = 64\n",
    "    gru_num_layers: int = 2\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    sample_rate: int = 16000\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "8838a605-1482-4c7f-a34c-4a03d4f676d0",
    "id": "KA1gPmE1h9pI"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "4wdu7k0ooeu2fglescr57v"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "class SpeechCommandDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transform: Optional[Callable] = None,\n",
    "        path2dir: str = None,\n",
    "        keywords: Union[str, List[str]] = None,\n",
    "        csv: Optional[pd.DataFrame] = None\n",
    "    ):        \n",
    "        self.transform = transform\n",
    "\n",
    "        if csv is None:\n",
    "            path2dir = pathlib.Path(path2dir)\n",
    "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
    "            \n",
    "            all_keywords = [\n",
    "                p.stem for p in path2dir.glob('*')\n",
    "                if p.is_dir() and not p.stem.startswith('_')\n",
    "            ]\n",
    "\n",
    "            triplets = []\n",
    "            for keyword in all_keywords:\n",
    "                paths = (path2dir / keyword).rglob('*.wav')\n",
    "                if keyword in keywords:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
    "                else:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
    "            \n",
    "            self.csv = pd.DataFrame(\n",
    "                triplets,\n",
    "                columns=['path', 'keyword', 'label']\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.csv = csv\n",
    "            \n",
    "    def __getitem__(self, index: int):\n",
    "        instance = self.csv.iloc[index]\n",
    "\n",
    "        path2wav = instance['path']\n",
    "        wav, sr = torchaudio.load(path2wav)\n",
    "        wav = wav.sum(dim=0)\n",
    "        \n",
    "        if self.transform:\n",
    "            wav = self.transform(wav)\n",
    "\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'keywors': instance['keyword'],\n",
    "            'label': instance['label']\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellId": "7b1450b2-cb28-4e71-9617-0c3cd86e8a8b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "QKgGdL8jh9pJ",
    "outputId": "faf10e67-60ce-4de9-f97a-39bcc81bfd24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58334</th>\n",
       "      <td>speech_commands/up/8a5acefd_nohash_0.wav</td>\n",
       "      <td>up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>speech_commands/sheila/d6b155a5_nohash_0.wav</td>\n",
       "      <td>sheila</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44575</th>\n",
       "      <td>speech_commands/five/d7ca14ef_nohash_0.wav</td>\n",
       "      <td>five</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48321</th>\n",
       "      <td>speech_commands/right/6add0595_nohash_1.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22522</th>\n",
       "      <td>speech_commands/go/f9318c93_nohash_0.wav</td>\n",
       "      <td>go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path keyword  label\n",
       "58334      speech_commands/up/8a5acefd_nohash_0.wav      up      0\n",
       "2928   speech_commands/sheila/d6b155a5_nohash_0.wav  sheila      1\n",
       "44575    speech_commands/five/d7ca14ef_nohash_0.wav    five      0\n",
       "48321   speech_commands/right/6add0595_nohash_1.wav   right      0\n",
       "22522      speech_commands/go/f9318c93_nohash_0.wav      go      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "dataset = SpeechCommandDataset(\n",
    "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
    ")\n",
    "\n",
    "dataset.csv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "jxvp74iwcpdcorlta40noq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "d3f99ea7-d46f-4a82-910d-c8c773a4d7be",
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "9531793c-262d-4df9-805b-0d1bb7fb1607",
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "class AugsCreation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "            'speech_commands/_background_noise_/white_noise.wav',\n",
    "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "            'speech_commands/_background_noise_/pink_noise.wav',\n",
    "            'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "\n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(\n",
    "            self.background_noises), size=(1,)).item()\n",
    "        noise = torchaudio.load(self.background_noises[noise_num])[0].squeeze()\n",
    "\n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * \\\n",
    "            torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(low=0, high=int(\n",
    "            noise.size(0) - audio.size(0) - 1), size=(1,)).item()\n",
    "        noise_sample = noise[start: start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "\n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellId": "42692c51-1016-4aaa-bb7a-183000ce0b46",
    "id": "ClWThxyYh9pM"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "indexes = torch.randperm(len(dataset))\n",
    "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
    "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
    "\n",
    "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
    "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)\n",
    "\n",
    "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
    "val_set = SpeechCommandDataset(csv=val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9cb87495-1cbb-4a61-afa5-2c28f50eb6a9",
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellId": "459b84b4-8cc1-42e0-b26c-9b3e28af876b",
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "ff2ead38-9c65-4085-ac3c-66c79e6cc8ec",
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "train_sampler = get_sampler(train_set.csv['label'].values)\n",
    "val_sampler = get_sampler(val_set.csv['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "8e9f2ade-c47c-4920-8683-8930a3dedfca",
    "id": "lyBqbxp0h9pO"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "class Collator:\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        wavs = []\n",
    "        labels = []    \n",
    "\n",
    "        for el in data:\n",
    "            wavs.append(el['wav'])\n",
    "            labels.append(el['label'])\n",
    "\n",
    "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "        wavs = pad_sequence(wavs, batch_first=True)    \n",
    "        labels = torch.Tensor(labels).long()\n",
    "        return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "661cd62e-0551-4868-96cf-0ca8ad0cf473",
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "cellId": "6tpxn7w9adlks0xwf4r92p"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
    "                          shuffle=False, collate_fn=Collator(),\n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=35, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
    "                        shuffle=False, collate_fn=Collator(),\n",
    "                        num_workers=35, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "4d9g1ccd62y9tauvfkmqr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "36ec5b97-cfd6-4c9b-99b6-ef013081ae2a",
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellId": "74259d9c-0838-4c25-86de-59807c63dd5f",
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "class LogMelspec:\n",
    "    def __init__(self, is_train, config):\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate=config.sample_rate,\n",
    "                    n_fft=400,\n",
    "                    win_length=400,\n",
    "                    hop_length=160,\n",
    "                    n_mels=config.n_mels\n",
    "                ),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_fft=400,\n",
    "                win_length=400,\n",
    "                hop_length=160,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # already on device\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellId": "66db8007-5404-4ce2-ad4f-95cf63018851",
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
    "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "26424a6c-583a-4755-844f-8723283cf14a",
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellId": "8aaf95da-9890-41e3-abd7-bd4c51fddc1f",
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellId": "6301db4a-e86b-4fb4-bbe0-4d01544820a7",
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "1089b5b7-f654-469d-a77d-0880fe884600",
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "cellId": "c6079a07-5353-4a96-9928-e409a707c9bf",
    "id": "UIT6STF_qUYl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
       "    (1): Flatten(start_dim=1, end_dim=2)\n",
       "  )\n",
       "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (attention): Attention(\n",
       "    (energy): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        energy = self.energy(input)\n",
    "        alpha = torch.softmax(energy, dim=-2)\n",
    "        return (input * alpha).sum(dim=-2)\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, config: TaskConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=config.cnn_out_channels,\n",
    "                kernel_size=config.kernel_size, stride=config.stride\n",
    "            ),\n",
    "            nn.Flatten(start_dim=1, end_dim=2),\n",
    "        )\n",
    "\n",
    "        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n",
    "            config.stride[0] + 1\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.conv_out_frequency * config.cnn_out_channels,\n",
    "            hidden_size=config.hidden_size,\n",
    "            num_layers=config.gru_num_layers,\n",
    "            dropout=0.1,\n",
    "            bidirectional=config.bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.unsqueeze(dim=1)\n",
    "        conv_output = self.conv(input).transpose(-1, -2)\n",
    "        gru_output, _ = self.gru(conv_output)\n",
    "        contex_vector = self.attention(gru_output)\n",
    "        output = self.classifier(contex_vector)\n",
    "                \n",
    "        return output\n",
    "\n",
    "config = TaskConfig()\n",
    "model = CRNN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellId": "6f1d1e93-bb10-43ae-a995-376954726f20"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class KDLoss(nn.KLDivLoss):\n",
    "    \"\"\"\n",
    "    \"Distilling the Knowledge in a Neural Network\"\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature, alpha=None, beta=None, reduction=None, **kwargs):\n",
    "        super().__init__(reduction=reduction)\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.beta = 1 - alpha if beta is None else beta\n",
    "\n",
    "    def forward(self, student_output, teacher_output, targets=None, *args, **kwargs):\n",
    "        soft_loss = super().forward(\n",
    "            torch.log_softmax(student_output / self.temperature, dim=1),\n",
    "            torch.softmax(teacher_output / self.temperature, dim=1)\n",
    "        )\n",
    "      \n",
    "        return (self.temperature ** 2) * soft_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "96fd7472-b88b-45e1-8757-daddfad56959",
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def train_epoch(model, opt, loader, log_melspec, device, distil=None):\n",
    "    if distil is not None:\n",
    "        teacher_model, alpha, distil_loss = distil\n",
    "    \n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        if distil is not None:\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher_model(batch)\n",
    "            \n",
    "            loss = loss * alpha + (1 - alpha) * distil_loss(teacher_logits, logits)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "a1e01971-0859-469f-831f-764639f0a330",
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, device, wandb=None):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        output = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    \n",
    "    if wandb is not None:\n",
    "        wandb.log({\n",
    "            \"au_fa_fr\": au_fa_fr,\n",
    "            \"mean_val_acc\": np.mean(accs),\n",
    "            \"mean_val_loss\": np.mean(val_losses)\n",
    "        })\n",
    "    \n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cellId": "dff9489f-c0ac-4279-963c-8d225da0e5ab",
    "id": "PpyvKwp0k3IU"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cellId": "75bc6301-06d7-46f6-9725-0290b934f580",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8sVpHNoocgA",
    "outputId": "91f2f178-98a6-448c-be99-80457a76ee4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
      "    (1): Flatten(start_dim=1, end_dim=2)\n",
      "  )\n",
      "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (attention): Attention(\n",
      "    (energy): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "config = TaskConfig()\n",
    "model = CRNN(config).to(config.device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellId": "wvc8qt56lpjhadamqszy"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellId": "31ob1a13xajmcaeeun1bx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/timothyxp/kws/runs/e3nec91d\" target=\"_blank\">good-night-17</a></strong> to <a href=\"https://wandb.ai/timothyxp/kws\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/timothyxp/kws/runs/e3nec91d?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0676aaf390>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import wandb\n",
    "\n",
    "wandb.init(project='kws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "sn26nepfpena5602cmdj4e"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "72f55b98-9aed-4454-8417-fa09a3d42977",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "32oooz4lqUYo",
    "outputId": "c4fdfc31-03fa-4540-9c03-4d72c6bdf714"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 39\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# TRAIN\n",
    "history = defaultdict(list)\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "\n",
    "    train_epoch(model, opt, train_loader,\n",
    "                melspec_train, TaskConfig.device)\n",
    "\n",
    "    au_fa_fr = validation(model, val_loader,\n",
    "                          melspec_val, TaskConfig.device, wandb=wandb)\n",
    "    history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "    }, f'base_model_{n}.pth')\n",
    "    \n",
    "    clear_output()\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "cellId": "h6fqovpq8ose1uc14yd6bq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:00, 105.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8851482808763522e-05"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "validation(\n",
    "    model, val_loader,\n",
    "    melspec_val, TaskConfig.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6g07fq6rujbqbouv6oj4a7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x4eot3413c7ks0rrxtjt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellId": "ke46jrldyxasbd9k2b54x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepconv prarams 808\n",
      "gru prarams 65280\n",
      "attn prarams 4225\n",
      "Head prarams 130\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "print(\"sepconv prarams\", count_parameters(model.conv))\n",
    "print(\"gru prarams\", count_parameters(model.gru))\n",
    "print(\"attn prarams\", count_parameters(model.attention))\n",
    "print(\"Head prarams\", count_parameters(model.classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "cellId": "uq7k1zcjxv1ub3crsc4u3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"base_model_39.pth\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "cellId": "2hoklpth17zssyoblyu5sr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hm7j03sjythuyg0d6qcx3p"
   },
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 1010])"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "cellId": "alc86irqsfe6eqviud5h",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "for i in range(12485, 12495):\n",
    "    sample = val_set[i]\n",
    "    #print(sample['keywors'])\n",
    "  #  print(sample['utt'].shape)\n",
    "    sample, label = Collator()([sample])\n",
    "    labels.append(label.item())\n",
    "    sample = melspec_val(sample.to(TaskConfig.device))\n",
    "    \n",
    "    samples.append(sample)\n",
    "    \n",
    "sample = torch.cat(samples, dim=-1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "cellId": "wz07ujdaludjjuw0tvg6dp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "class KWSDecoder:\n",
    "    def __init__(self, model, config, window_size=60):\n",
    "        self.model = model\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.receptive_field = config.kernel_size[1]\n",
    "\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.buffer = None\n",
    "        self.attn_buffer = []\n",
    "        self.gru_outputs = []\n",
    "        self.probas = torch.zeros((1,)).to(TaskConfig.device)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(TaskConfig.gru_num_layers, 1, TaskConfig.hidden_size).to(TaskConfig.device)\n",
    "         \n",
    "        input = input.unsqueeze(dim=1)\n",
    "        # batch_size, n_channels, mels, len\n",
    "        \n",
    "        conv_output = self.conv(input).transpose(-1, -2)\n",
    "        # batch_size, len, hidden\n",
    "        \n",
    "        gru_output, _ = self.gru(conv_output)\n",
    "        # batch_size, len, hidden\n",
    "        \n",
    "        contex_vector = self.attention(gru_output)\n",
    "        # batch_size, hidden\n",
    "        \n",
    "        output = self.classifier(contex_vector)\n",
    "        # batch_size, proba\n",
    "        \n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def decode(self, x):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        \n",
    "        if self.buffer is None:\n",
    "            self.buffer = x\n",
    "        else:\n",
    "            self.buffer = torch.cat((self.buffer, x), dim=-1)\n",
    "            \n",
    "        if self.buffer.shape[-1] < self.receptive_field:\n",
    "            return\n",
    "            \n",
    "        self.buffer = self.buffer[:, :, :, -self.receptive_field:]\n",
    "        print(\"buffer\", self.buffer.shape)\n",
    "                    \n",
    "        output = self.model.conv(self.buffer).transpose(-1, -2)\n",
    "        print(\"conv output\", output.shape)\n",
    "        \n",
    "        output, hidden = self.model.gru(output, self.hidden)\n",
    "        # output (1, 1, hidden_size)\n",
    "        self.hidden = hidden\n",
    "        print(\"gru out\", output.shape)\n",
    "        \n",
    "        self.gru_outputs.append(output)\n",
    "        \n",
    "        if len(self.gru_outputs) > self.window_size:\n",
    "            self.gru_outputs = self.gru_outputs[1:]\n",
    "        \n",
    "        output = torch.cat(self.gru_outputs, dim=1)\n",
    "        \n",
    "        print(\"attn input\", output.shape)\n",
    "        \n",
    "        contex_vector = self.model.attention(output)\n",
    "        print(\"attn out\", contex_vector.shape)\n",
    "        \n",
    "        proba = self.model.classifier(contex_vector)\n",
    "        print(\"proba\", proba.shape)\n",
    "        proba = F.softmax(proba)[0][1]\n",
    "        \n",
    "        self.probas = torch.cat((self.probas, proba.unsqueeze(0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "cellId": "l31akrxw75hi7u9f7rgk9s"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "memory_size = 11\n",
    "decoder = KWSDecoder(model, config, window_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "cellId": "n867rseb48ehf6nfziwshn",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 1, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 2, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 3, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 4, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 5, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 6, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 7, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 8, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 9, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 10, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n",
      "buffer torch.Size([1, 1, 40, 20])\n",
      "conv output torch.Size([1, 1, 144])\n",
      "gru out torch.Size([1, 1, 64])\n",
      "attn input torch.Size([1, 11, 64])\n",
      "attn out torch.Size([1, 64])\n",
      "proba torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "step = config.stride[1]\n",
    "\n",
    "for i in range(0, sample.shape[2], step):\n",
    "    decoder.decode(sample[:, :, i:i+step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "cellId": "thux13r6r9srmqdclwvb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "cellId": "l4xowv25bvehctj1gdpdk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "window_size = 10\n",
    "left_x = (labels.index(1) * 101) // step \n",
    "right_x = (labels.index(1) + 1) * 101 // step\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(decoder.probas.shape[0] - window_size + 1),\n",
    "    moving_average(decoder.probas.cpu().numpy(), window_size)\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    [left_x, left_x, right_x, right_x, left_x],\n",
    "    [0,1,1,0,0],\n",
    "    c='g',\n",
    "    linestyle='dashed'\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlabel=f'Frame, step={step}',\n",
    "    ylabel='Proba of keyword'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "z2a1895grsap4h6s9r7vt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "18k5np5xlfy4jfsrzlww0v"
   },
   "source": [
    "# Compresing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cellId": "xy2gtn5jxvc3zl6hcqvug7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import time\n",
    "from thop import profile, clever_format, rnn_hooks\n",
    "\n",
    "\n",
    "def get_size_in_megabytes(model):\n",
    "    num_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    param_size = next(model.parameters()).element_size()\n",
    "    return (num_params * param_size) / (2 ** 20)\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, name: str, verbose=False):\n",
    "        self.name = name\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.t = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.t = time.time() - self.t\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"{self.name.capitalize()} | Elapsed time : {self.t:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "b8onmbmlymiy57ygqh7ix",
    "tags": []
   },
   "source": [
    "## Базовый сценарий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "cellId": "f16wx2f9t6w4v4spqwrzec"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# берем один бач и гоняем на нем, тк датасфера на даталоадерах постоянно непредсказуемо подвисает\n",
    "inference_device = 'cpu'\n",
    "\n",
    "melspec_inf = LogMelspec(is_train=False, config=TaskConfig)\n",
    "melspec_inf.melspec.to(inference_device)\n",
    "\n",
    "batch, labels = next(iter(val_loader))\n",
    "batch, labels = batch.to(inference_device), labels.to(inference_device)\n",
    "batch = melspec_inf(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cellId": "cmh3bb71ohqdi9i50gdn0i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# base model\n",
    "def get_base_model():\n",
    "    config = TaskConfig()\n",
    "    model = CRNN(config).to(config.device)\n",
    "    model.load_state_dict(torch.load(\"base_model_39.pth\")['model_state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "base_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "cellId": "6y1nkqyhk15x8xts144e5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def report_model(model, batch, device, model_name=\"Base\", n_batches=1000, wandb=None):\n",
    "    model = model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    print(f\"Profile Model {model_name}\")\n",
    "    macs_number, params_number = profile(model, (batch, )) \n",
    "    macs, params = clever_format([macs_number, params_number], \"%3f\")\n",
    "    print(f\"Macs - {macs}, params - {params}\")\n",
    "\n",
    "    model_size = get_size_in_megabytes(model)\n",
    "    print(f\"Model size - {model_size} Mb\")\n",
    "                \n",
    "    au_fa_fr = validation(model, val_loader,\n",
    "                          melspec_inf, inference_device)\n",
    "    print(\"AU_FA_FR\", au_fa_fr)\n",
    "    \n",
    "    if wandb is not None:\n",
    "        wandb.log({\n",
    "            \"val_au_fa_fr\": au_fa_fr,\n",
    "            \"Macs\": macs_number,\n",
    "            \"Params\": params_number,\n",
    "            \"size\": model_size\n",
    "        })\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cellId": "ljpafqvccta3o5vb4hmc44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile Model Base\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Attention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.CRNN'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Macs - 119.527424M, params - 70.443000K\n",
      "Model size - 0.2687187194824219 Mb\n",
      "Batch time | Elapsed time : 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:02, 39.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU_FA_FR 1.8851482808763522e-05\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "report_model(base_model, batch, inference_device, wandb=wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "cellId": "emabojvw4bnnzcqhg71xj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дистиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "cellId": "ya86ph4amqvfkbpmkrxg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def train_model(distil_model, opt, config, model, name=None, wandb=None):\n",
    "    if name is None:\n",
    "        name = ''\n",
    "        \n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for n in range(config.num_epochs):\n",
    "        train_epoch(\n",
    "            distil_model, opt, train_loader,\n",
    "            melspec_train, config.device,\n",
    "            distil=(\n",
    "                model.to(config.device),\n",
    "                config.distil_alpha,\n",
    "                KDLoss(5, config.distil_alpha, reduction='mean')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': distil_model.state_dict(),\n",
    "        }, f'models/distil_model_{name}_{n}.pth')\n",
    "        \n",
    "        if n % config.val_every_epoch == 0:\n",
    "            au_fa_fr = validation(distil_model, val_loader,\n",
    "                                  melspec_val, config.device, wandb=wandb)\n",
    "            history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "            clear_output()\n",
    "            plt.plot(history['val_metric'])\n",
    "            plt.ylabel('Metric')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "            print('END OF EPOCH', n)\n",
    "\n",
    "def train(config, name=None):\n",
    "    distil_model = CRNN(config).to(config.device)\n",
    "\n",
    "  #  print(distil_model)\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        distil_model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    wandb.init(\n",
    "        project='kws',\n",
    "        name=name,\n",
    "        config=config.__dict__\n",
    "    )\n",
    "    \n",
    "    train_model(distil_model, opt, config, model, wandb=wandb, name=name)\n",
    "    \n",
    "    return distil_model, wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DistilTaskConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    num_epochs: int = 100\n",
    "    n_mels: int = 40\n",
    "    cnn_out_channels: int = 6\n",
    "    kernel_size: Tuple[int, int] = (5, 25)\n",
    "    stride: Tuple[int, int] = (2, 12)\n",
    "    hidden_size: int = 20\n",
    "    gru_num_layers: int = 1\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    val_every_epoch: int = 3\n",
    "    sample_rate: int = 16000\n",
    "    distil_alpha = 0.9\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [00:05, 36.16it/s]\n",
      "Exception in thread Thread-3456:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76/3488272750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mdistil_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"chan={cnn_channel}, kernel={kernel}, hidden={hidden}, stride={stride}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mreport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistil_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76/1474041397.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistil_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistil_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76/1474041397.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(distil_model, opt, config, model, name, wandb)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistil_alpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mKDLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistil_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             )\n\u001b[1;32m     18\u001b[0m         )\n",
      "\u001b[0;32m/tmp/ipykernel_76/3143510600.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, opt, loader, log_melspec, device, distil)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_exp = 0\n",
    "skip_exps = 1\n",
    "\n",
    "for cnn_channel in [2, 3, 4]:\n",
    "    for kernel in [20, 25]:\n",
    "        for hidden in [12, 16, 20]:\n",
    "            for stride in [6]:\n",
    "                n_exp += 1\n",
    "                \n",
    "                if n_exp <= skip_exps:\n",
    "                    continue\n",
    "                    \n",
    "                config = DistilTaskConfig(\n",
    "                    cnn_out_channels=cnn_channel,\n",
    "                    kernel_size=(5, kernel),\n",
    "                    hidden_size=hidden,\n",
    "                    stride=(2, stride)\n",
    "                )\n",
    "\n",
    "                distil_model, wandb = train(config, f\"chan={cnn_channel}, kernel={kernel}, hidden={hidden}, stride={stride}\")\n",
    "\n",
    "                report_model(distil_model, batch, inference_device, wandb=wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "cellId": "dkl89bxsoznm2vhjyupp6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "distil_model.load_state_dict(torch.load(\"best_distil_20_2_12.pth\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile Model Base\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Attention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.CRNN'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Macs - 119.527424M, params - 70.443000K\n",
      "Model size - 0.2687187194824219 Mb\n",
      "Batch time | Elapsed time : 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:00, 102.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU_FA_FR 1.8851482808763522e-05\n"
     ]
    }
   ],
   "source": [
    "report_model(model, batch, inference_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 2, kernel_size=(5, 20), stride=(2, 6))\n",
       "    (1): Flatten(start_dim=1, end_dim=2)\n",
       "  )\n",
       "  (gru): GRU(36, 16, batch_first=True, dropout=0.1)\n",
       "  (attention): Attention(\n",
       "    (energy): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': distil_model.state_dict(),\n",
    "}, f'models/best_distil_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "cellId": "etu5no7dcye4fxely9zezx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile Model Base\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Attention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.CRNN'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Macs - 11.852800M, params - 3.117000K\n",
      "Model size - 0.011890411376953125 Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:04, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU_FA_FR 3.590076624802828e-05\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "report_model(distil_model, batch, inference_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "cellId": "ysz4yifuofe4hsxca9ijmq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.772771186440675"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2687187 / 0.0118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "cellId": "gpqa10uypqpwr3hxt9i0co"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.084373945325682"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "119.52 / 11.852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Квантизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 2, kernel_size=(5, 20), stride=(2, 6))\n",
       "    (1): Flatten(start_dim=1, end_dim=2)\n",
       "  )\n",
       "  (gru): DynamicQuantizedGRU(36, 16, batch_first=True, dropout=0.1)\n",
       "  (attention): Attention(\n",
       "    (energy): Sequential(\n",
       "      (0): DynamicQuantizedLinear(in_features=16, out_features=16, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "      (1): Tanh()\n",
       "      (2): DynamicQuantizedLinear(in_features=16, out_features=1, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    )\n",
       "  )\n",
       "  (classifier): DynamicQuantizedLinear(in_features=16, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       ")"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.quantization\n",
    "\n",
    "quantizated_model = torch.quantization.quantize_dynamic(distil_model.cpu())\n",
    "\n",
    "quantizated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizated_model = quantizated_model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать Macs таким же как и обычной модели, памяти посчитаем по чекпоинту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:02, 34.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.9493229891863565e-05"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(\n",
    "    quantizated_model, val_loader,\n",
    "    melspec_inf, 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00077056884765625"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_size_in_megabytes(quantizated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizated_model.state_dict()['attention.energy.0._packed_params._packed_params'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0485, -0.5554,  0.1190, -0.0573,  0.0485, -0.2204, -0.3394,  0.0970,\n",
       "         -0.0220,  0.0044, -0.1807,  0.1895,  0.0926,  0.1014,  0.5554, -0.0485],\n",
       "        [ 0.4143, -0.5554,  0.3482, -0.1895, -0.1234,  0.1499,  0.0573, -0.0793,\n",
       "         -0.1719, -0.1411,  0.0176,  0.2997,  0.3835,  0.1014,  0.4628, -0.1411],\n",
       "        [ 0.3394, -0.1587,  0.2380, -0.4452, -0.1851,  0.1278, -0.2821,  0.0573,\n",
       "         -0.1851,  0.1058, -0.0485, -0.0705,  0.1675, -0.3438, -0.3526,  0.1058],\n",
       "        [ 0.1190,  0.2777, -0.1587,  0.4276,  0.1719, -0.1675, -0.1455,  0.1543,\n",
       "          0.1763,  0.0617, -0.1763,  0.0926, -0.5245, -0.0749, -0.4188,  0.1807],\n",
       "        [ 0.0264,  0.4320, -0.3350,  0.1807, -0.1411,  0.1234,  0.1895, -0.2689,\n",
       "          0.1631, -0.0353,  0.0000, -0.0441, -0.0353, -0.0882, -0.3659,  0.2468],\n",
       "        [ 0.4628,  0.0088,  0.2072, -0.4099, -0.4276,  0.2645, -0.2821,  0.2292,\n",
       "          0.0132,  0.2953, -0.2160, -0.2821, -0.0926,  0.0264, -0.4849,  0.5598],\n",
       "        [-0.1366,  0.2909, -0.0970,  0.4011,  0.2909, -0.2557, -0.1939,  0.1366,\n",
       "          0.1719,  0.1939, -0.2116,  0.0882, -0.4496, -0.0088, -0.4628,  0.2513],\n",
       "        [ 0.1190, -0.3394,  0.0749, -0.3747,  0.0176, -0.0573, -0.1939, -0.2601,\n",
       "          0.0176, -0.1014, -0.0264, -0.1499,  0.5245, -0.0617,  0.0882, -0.1499],\n",
       "        [ 0.4188, -0.1190, -0.0617, -0.2380,  0.0309,  0.3086, -0.3570,  0.2336,\n",
       "         -0.0132,  0.2028, -0.2997, -0.1851,  0.1278,  0.1234, -0.2336,  0.3659],\n",
       "        [ 0.2909, -0.0882,  0.2733,  0.0838, -0.2601, -0.1411, -0.1807, -0.2953,\n",
       "         -0.3174,  0.1807,  0.0176,  0.3041,  0.0705,  0.0661,  0.1807, -0.1675],\n",
       "        [-0.0132, -0.4717,  0.2424, -0.3526,  0.1014, -0.1455, -0.0661, -0.2777,\n",
       "         -0.3130, -0.1146, -0.2248, -0.1763,  0.4276, -0.1631,  0.1939,  0.1631],\n",
       "        [-0.2645,  0.3967,  0.1719,  0.3218,  0.2292,  0.1366,  0.2204,  0.2689,\n",
       "          0.1719, -0.0970,  0.0397, -0.2513, -0.1190,  0.3526, -0.2953, -0.1807],\n",
       "        [ 0.0088,  0.2865, -0.1058,  0.2072,  0.1851,  0.0882, -0.1939, -0.1366,\n",
       "         -0.0176, -0.1102, -0.1278, -0.0397, -0.4011, -0.1763, -0.2380,  0.3130],\n",
       "        [ 0.4672, -0.2424, -0.0749, -0.2689,  0.1499, -0.0838, -0.2380, -0.0044,\n",
       "         -0.3350,  0.2997,  0.1543,  0.2468,  0.2777,  0.1146,  0.0000,  0.0132],\n",
       "        [ 0.0882,  0.2557, -0.0441,  0.0309,  0.1058, -0.0176,  0.0176,  0.2689,\n",
       "         -0.1366, -0.1146,  0.1984, -0.0309, -0.2601,  0.2645, -0.2953, -0.0529],\n",
       "        [ 0.1675, -0.4055,  0.1499, -0.1366,  0.0705,  0.1322,  0.0970, -0.0441,\n",
       "         -0.3570,  0.2248, -0.0132, -0.0176,  0.0926,  0.0044,  0.1278,  0.0926]],\n",
       "       size=(16, 16), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.004407947883009911,\n",
       "       zero_point=0)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizated_model.attention.energy[0].weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мерим память по честному"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:    \t Size (KB): 288.87\n"
     ]
    }
   ],
   "source": [
    "model_size = print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:    \t Size (KB): 19.549\n"
     ]
    }
   ],
   "source": [
    "distil_model_size = print_size_of_model(distil_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:    \t Size (KB): 13.579\n"
     ]
    }
   ],
   "source": [
    "quant_model_size = print_size_of_model(quantizated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:    \t Size (KB): 2.015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_size_of_model(quantizated_model.attention.energy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.776714921479359, 21.273289638412255)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size / distil_model_size, model_size / quant_model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "notebookId": "42a0f5dc-5a24-4a87-9f4b-51e91386449e",
  "notebookPath": "seminar.ipynb",
  "ydsNotebookPath": "seminar.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
